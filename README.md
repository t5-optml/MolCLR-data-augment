Augmentation Strategy: Random Edge Feature Perturbation

To generate augmented views for contrastive pre-training within the MolCLR framework, we implemented a novel edge augmentation strategy termed "Random Edge Feature Perturbation". Standard molecular graph representations typically use 2-dimensional edge attributes encoding bond type and bond direction. Our approach extends this by introducing a third, continuous feature channel. This new channel is populated with random values sampled from a standard Gaussian distribution (mean 0, variance 1), subsequently scaled by a controllable hyperparameter, perturbation_scale. The GNN models (both GIN and GCN variants) were adapted accordingly; specifically, their convolutional layers incorporate an MLP-based edge encoder capable of processing these 3-dimensional edge attributes, learning a unified embedding from the discrete bond type/direction and the added continuous noise feature.

For each molecule during pre-training, two augmented views are created by applying this perturbation independently, resulting in different random noise values in the third edge feature channel for each view. The NT-Xent contrastive loss then encourages the model to map these two differently perturbed views of the same molecule to similar points in the representation space, while pushing them apart from representations of other molecules. This process implicitly trains the model to learn representations that are invariant to the specific random noise added to the edge features, forcing it to focus on more stable structural and chemical information inherent in the node features, graph connectivity, and the original edge features. Notably, empirical results during development indicated that this relatively simple random noise addition yielded better downstream fine-tuning performance compared to initial experiments involving more complex edge perturbations weighted by graph spectral properties derived from the Laplacian.
